{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "import torch\n",
    "import sys\n",
    "import argparse\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Model,AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.31.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"gpt2\")\n",
    "#m=GPT2Model(config)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0-11): 12 x GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (act): NewGELUActivation()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|██████████| 268M/268M [00:03<00:00, 68.1MB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, DistilBertConfig\n",
    "distilbertconfig=AutoConfig.from_pretrained(\"distilbert-base-uncased\")\n",
    "m2=AutoModelForMaskedLM.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.31.0\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Instantiate one of the configuration classes of the library from a pretrained model configuration.\n",
      "\n",
      "The configuration class to instantiate is selected based on the `model_type` property of the config object that\n",
      "is loaded, or when it's missing, by falling back to using pattern matching on `pretrained_model_name_or_path`:\n",
      "\n",
      "    - **albert** -- [`AlbertConfig`] (ALBERT model)\n",
      "    - **align** -- [`AlignConfig`] (ALIGN model)\n",
      "    - **altclip** -- [`AltCLIPConfig`] (AltCLIP model)\n",
      "    - **audio-spectrogram-transformer** -- [`ASTConfig`] (Audio Spectrogram Transformer model)\n",
      "    - **autoformer** -- [`AutoformerConfig`] (Autoformer model)\n",
      "    - **bark** -- [`BarkConfig`] (Bark model)\n",
      "    - **bart** -- [`BartConfig`] (BART model)\n",
      "    - **beit** -- [`BeitConfig`] (BEiT model)\n",
      "    - **bert** -- [`BertConfig`] (BERT model)\n",
      "    - **bert-generation** -- [`BertGenerationConfig`] (Bert Generation model)\n",
      "    - **big_bird** -- [`BigBirdConfig`] (BigBird model)\n",
      "    - **bigbird_pegasus** -- [`BigBirdPegasusConfig`] (BigBird-Pegasus model)\n",
      "    - **biogpt** -- [`BioGptConfig`] (BioGpt model)\n",
      "    - **bit** -- [`BitConfig`] (BiT model)\n",
      "    - **blenderbot** -- [`BlenderbotConfig`] (Blenderbot model)\n",
      "    - **blenderbot-small** -- [`BlenderbotSmallConfig`] (BlenderbotSmall model)\n",
      "    - **blip** -- [`BlipConfig`] (BLIP model)\n",
      "    - **blip-2** -- [`Blip2Config`] (BLIP-2 model)\n",
      "    - **bloom** -- [`BloomConfig`] (BLOOM model)\n",
      "    - **bridgetower** -- [`BridgeTowerConfig`] (BridgeTower model)\n",
      "    - **camembert** -- [`CamembertConfig`] (CamemBERT model)\n",
      "    - **canine** -- [`CanineConfig`] (CANINE model)\n",
      "    - **chinese_clip** -- [`ChineseCLIPConfig`] (Chinese-CLIP model)\n",
      "    - **clap** -- [`ClapConfig`] (CLAP model)\n",
      "    - **clip** -- [`CLIPConfig`] (CLIP model)\n",
      "    - **clipseg** -- [`CLIPSegConfig`] (CLIPSeg model)\n",
      "    - **codegen** -- [`CodeGenConfig`] (CodeGen model)\n",
      "    - **conditional_detr** -- [`ConditionalDetrConfig`] (Conditional DETR model)\n",
      "    - **convbert** -- [`ConvBertConfig`] (ConvBERT model)\n",
      "    - **convnext** -- [`ConvNextConfig`] (ConvNeXT model)\n",
      "    - **convnextv2** -- [`ConvNextV2Config`] (ConvNeXTV2 model)\n",
      "    - **cpmant** -- [`CpmAntConfig`] (CPM-Ant model)\n",
      "    - **ctrl** -- [`CTRLConfig`] (CTRL model)\n",
      "    - **cvt** -- [`CvtConfig`] (CvT model)\n",
      "    - **data2vec-audio** -- [`Data2VecAudioConfig`] (Data2VecAudio model)\n",
      "    - **data2vec-text** -- [`Data2VecTextConfig`] (Data2VecText model)\n",
      "    - **data2vec-vision** -- [`Data2VecVisionConfig`] (Data2VecVision model)\n",
      "    - **deberta** -- [`DebertaConfig`] (DeBERTa model)\n",
      "    - **deberta-v2** -- [`DebertaV2Config`] (DeBERTa-v2 model)\n",
      "    - **decision_transformer** -- [`DecisionTransformerConfig`] (Decision Transformer model)\n",
      "    - **deformable_detr** -- [`DeformableDetrConfig`] (Deformable DETR model)\n",
      "    - **deit** -- [`DeiTConfig`] (DeiT model)\n",
      "    - **deta** -- [`DetaConfig`] (DETA model)\n",
      "    - **detr** -- [`DetrConfig`] (DETR model)\n",
      "    - **dinat** -- [`DinatConfig`] (DiNAT model)\n",
      "    - **distilbert** -- [`DistilBertConfig`] (DistilBERT model)\n",
      "    - **donut-swin** -- [`DonutSwinConfig`] (DonutSwin model)\n",
      "    - **dpr** -- [`DPRConfig`] (DPR model)\n",
      "    - **dpt** -- [`DPTConfig`] (DPT model)\n",
      "    - **efficientformer** -- [`EfficientFormerConfig`] (EfficientFormer model)\n",
      "    - **efficientnet** -- [`EfficientNetConfig`] (EfficientNet model)\n",
      "    - **electra** -- [`ElectraConfig`] (ELECTRA model)\n",
      "    - **encodec** -- [`EncodecConfig`] (EnCodec model)\n",
      "    - **encoder-decoder** -- [`EncoderDecoderConfig`] (Encoder decoder model)\n",
      "    - **ernie** -- [`ErnieConfig`] (ERNIE model)\n",
      "    - **ernie_m** -- [`ErnieMConfig`] (ErnieM model)\n",
      "    - **esm** -- [`EsmConfig`] (ESM model)\n",
      "    - **falcon** -- [`FalconConfig`] (Falcon model)\n",
      "    - **flaubert** -- [`FlaubertConfig`] (FlauBERT model)\n",
      "    - **flava** -- [`FlavaConfig`] (FLAVA model)\n",
      "    - **fnet** -- [`FNetConfig`] (FNet model)\n",
      "    - **focalnet** -- [`FocalNetConfig`] (FocalNet model)\n",
      "    - **fsmt** -- [`FSMTConfig`] (FairSeq Machine-Translation model)\n",
      "    - **funnel** -- [`FunnelConfig`] (Funnel Transformer model)\n",
      "    - **git** -- [`GitConfig`] (GIT model)\n",
      "    - **glpn** -- [`GLPNConfig`] (GLPN model)\n",
      "    - **gpt-sw3** -- [`GPT2Config`] (GPT-Sw3 model)\n",
      "    - **gpt2** -- [`GPT2Config`] (OpenAI GPT-2 model)\n",
      "    - **gpt_bigcode** -- [`GPTBigCodeConfig`] (GPTBigCode model)\n",
      "    - **gpt_neo** -- [`GPTNeoConfig`] (GPT Neo model)\n",
      "    - **gpt_neox** -- [`GPTNeoXConfig`] (GPT NeoX model)\n",
      "    - **gpt_neox_japanese** -- [`GPTNeoXJapaneseConfig`] (GPT NeoX Japanese model)\n",
      "    - **gptj** -- [`GPTJConfig`] (GPT-J model)\n",
      "    - **gptsan-japanese** -- [`GPTSanJapaneseConfig`] (GPTSAN-japanese model)\n",
      "    - **graphormer** -- [`GraphormerConfig`] (Graphormer model)\n",
      "    - **groupvit** -- [`GroupViTConfig`] (GroupViT model)\n",
      "    - **hubert** -- [`HubertConfig`] (Hubert model)\n",
      "    - **ibert** -- [`IBertConfig`] (I-BERT model)\n",
      "    - **imagegpt** -- [`ImageGPTConfig`] (ImageGPT model)\n",
      "    - **informer** -- [`InformerConfig`] (Informer model)\n",
      "    - **instructblip** -- [`InstructBlipConfig`] (InstructBLIP model)\n",
      "    - **jukebox** -- [`JukeboxConfig`] (Jukebox model)\n",
      "    - **layoutlm** -- [`LayoutLMConfig`] (LayoutLM model)\n",
      "    - **layoutlmv2** -- [`LayoutLMv2Config`] (LayoutLMv2 model)\n",
      "    - **layoutlmv3** -- [`LayoutLMv3Config`] (LayoutLMv3 model)\n",
      "    - **led** -- [`LEDConfig`] (LED model)\n",
      "    - **levit** -- [`LevitConfig`] (LeViT model)\n",
      "    - **lilt** -- [`LiltConfig`] (LiLT model)\n",
      "    - **llama** -- [`LlamaConfig`] (LLaMA model)\n",
      "    - **longformer** -- [`LongformerConfig`] (Longformer model)\n",
      "    - **longt5** -- [`LongT5Config`] (LongT5 model)\n",
      "    - **luke** -- [`LukeConfig`] (LUKE model)\n",
      "    - **lxmert** -- [`LxmertConfig`] (LXMERT model)\n",
      "    - **m2m_100** -- [`M2M100Config`] (M2M100 model)\n",
      "    - **marian** -- [`MarianConfig`] (Marian model)\n",
      "    - **markuplm** -- [`MarkupLMConfig`] (MarkupLM model)\n",
      "    - **mask2former** -- [`Mask2FormerConfig`] (Mask2Former model)\n",
      "    - **maskformer** -- [`MaskFormerConfig`] (MaskFormer model)\n",
      "    - **maskformer-swin** -- [`MaskFormerSwinConfig`] (MaskFormerSwin model)\n",
      "    - **mbart** -- [`MBartConfig`] (mBART model)\n",
      "    - **mctct** -- [`MCTCTConfig`] (M-CTC-T model)\n",
      "    - **mega** -- [`MegaConfig`] (MEGA model)\n",
      "    - **megatron-bert** -- [`MegatronBertConfig`] (Megatron-BERT model)\n",
      "    - **mgp-str** -- [`MgpstrConfig`] (MGP-STR model)\n",
      "    - **mobilebert** -- [`MobileBertConfig`] (MobileBERT model)\n",
      "    - **mobilenet_v1** -- [`MobileNetV1Config`] (MobileNetV1 model)\n",
      "    - **mobilenet_v2** -- [`MobileNetV2Config`] (MobileNetV2 model)\n",
      "    - **mobilevit** -- [`MobileViTConfig`] (MobileViT model)\n",
      "    - **mobilevitv2** -- [`MobileViTV2Config`] (MobileViTV2 model)\n",
      "    - **mpnet** -- [`MPNetConfig`] (MPNet model)\n",
      "    - **mra** -- [`MraConfig`] (MRA model)\n",
      "    - **mt5** -- [`MT5Config`] (MT5 model)\n",
      "    - **musicgen** -- [`MusicgenConfig`] (MusicGen model)\n",
      "    - **mvp** -- [`MvpConfig`] (MVP model)\n",
      "    - **nat** -- [`NatConfig`] (NAT model)\n",
      "    - **nezha** -- [`NezhaConfig`] (Nezha model)\n",
      "    - **nllb-moe** -- [`NllbMoeConfig`] (NLLB-MOE model)\n",
      "    - **nystromformer** -- [`NystromformerConfig`] (Nyströmformer model)\n",
      "    - **oneformer** -- [`OneFormerConfig`] (OneFormer model)\n",
      "    - **open-llama** -- [`OpenLlamaConfig`] (OpenLlama model)\n",
      "    - **openai-gpt** -- [`OpenAIGPTConfig`] (OpenAI GPT model)\n",
      "    - **opt** -- [`OPTConfig`] (OPT model)\n",
      "    - **owlvit** -- [`OwlViTConfig`] (OWL-ViT model)\n",
      "    - **pegasus** -- [`PegasusConfig`] (Pegasus model)\n",
      "    - **pegasus_x** -- [`PegasusXConfig`] (PEGASUS-X model)\n",
      "    - **perceiver** -- [`PerceiverConfig`] (Perceiver model)\n",
      "    - **pix2struct** -- [`Pix2StructConfig`] (Pix2Struct model)\n",
      "    - **plbart** -- [`PLBartConfig`] (PLBart model)\n",
      "    - **poolformer** -- [`PoolFormerConfig`] (PoolFormer model)\n",
      "    - **prophetnet** -- [`ProphetNetConfig`] (ProphetNet model)\n",
      "    - **qdqbert** -- [`QDQBertConfig`] (QDQBert model)\n",
      "    - **rag** -- [`RagConfig`] (RAG model)\n",
      "    - **realm** -- [`RealmConfig`] (REALM model)\n",
      "    - **reformer** -- [`ReformerConfig`] (Reformer model)\n",
      "    - **regnet** -- [`RegNetConfig`] (RegNet model)\n",
      "    - **rembert** -- [`RemBertConfig`] (RemBERT model)\n",
      "    - **resnet** -- [`ResNetConfig`] (ResNet model)\n",
      "    - **retribert** -- [`RetriBertConfig`] (RetriBERT model)\n",
      "    - **roberta** -- [`RobertaConfig`] (RoBERTa model)\n",
      "    - **roberta-prelayernorm** -- [`RobertaPreLayerNormConfig`] (RoBERTa-PreLayerNorm model)\n",
      "    - **roc_bert** -- [`RoCBertConfig`] (RoCBert model)\n",
      "    - **roformer** -- [`RoFormerConfig`] (RoFormer model)\n",
      "    - **rwkv** -- [`RwkvConfig`] (RWKV model)\n",
      "    - **sam** -- [`SamConfig`] (SAM model)\n",
      "    - **segformer** -- [`SegformerConfig`] (SegFormer model)\n",
      "    - **sew** -- [`SEWConfig`] (SEW model)\n",
      "    - **sew-d** -- [`SEWDConfig`] (SEW-D model)\n",
      "    - **speech-encoder-decoder** -- [`SpeechEncoderDecoderConfig`] (Speech Encoder decoder model)\n",
      "    - **speech_to_text** -- [`Speech2TextConfig`] (Speech2Text model)\n",
      "    - **speech_to_text_2** -- [`Speech2Text2Config`] (Speech2Text2 model)\n",
      "    - **speecht5** -- [`SpeechT5Config`] (SpeechT5 model)\n",
      "    - **splinter** -- [`SplinterConfig`] (Splinter model)\n",
      "    - **squeezebert** -- [`SqueezeBertConfig`] (SqueezeBERT model)\n",
      "    - **swiftformer** -- [`SwiftFormerConfig`] (SwiftFormer model)\n",
      "    - **swin** -- [`SwinConfig`] (Swin Transformer model)\n",
      "    - **swin2sr** -- [`Swin2SRConfig`] (Swin2SR model)\n",
      "    - **swinv2** -- [`Swinv2Config`] (Swin Transformer V2 model)\n",
      "    - **switch_transformers** -- [`SwitchTransformersConfig`] (SwitchTransformers model)\n",
      "    - **t5** -- [`T5Config`] (T5 model)\n",
      "    - **table-transformer** -- [`TableTransformerConfig`] (Table Transformer model)\n",
      "    - **tapas** -- [`TapasConfig`] (TAPAS model)\n",
      "    - **time_series_transformer** -- [`TimeSeriesTransformerConfig`] (Time Series Transformer model)\n",
      "    - **timesformer** -- [`TimesformerConfig`] (TimeSformer model)\n",
      "    - **timm_backbone** -- [`TimmBackboneConfig`] (TimmBackbone model)\n",
      "    - **trajectory_transformer** -- [`TrajectoryTransformerConfig`] (Trajectory Transformer model)\n",
      "    - **transfo-xl** -- [`TransfoXLConfig`] (Transformer-XL model)\n",
      "    - **trocr** -- [`TrOCRConfig`] (TrOCR model)\n",
      "    - **tvlt** -- [`TvltConfig`] (TVLT model)\n",
      "    - **umt5** -- [`UMT5Config`] (UMT5 model)\n",
      "    - **unispeech** -- [`UniSpeechConfig`] (UniSpeech model)\n",
      "    - **unispeech-sat** -- [`UniSpeechSatConfig`] (UniSpeechSat model)\n",
      "    - **upernet** -- [`UperNetConfig`] (UPerNet model)\n",
      "    - **van** -- [`VanConfig`] (VAN model)\n",
      "    - **videomae** -- [`VideoMAEConfig`] (VideoMAE model)\n",
      "    - **vilt** -- [`ViltConfig`] (ViLT model)\n",
      "    - **vision-encoder-decoder** -- [`VisionEncoderDecoderConfig`] (Vision Encoder decoder model)\n",
      "    - **vision-text-dual-encoder** -- [`VisionTextDualEncoderConfig`] (VisionTextDualEncoder model)\n",
      "    - **visual_bert** -- [`VisualBertConfig`] (VisualBERT model)\n",
      "    - **vit** -- [`ViTConfig`] (ViT model)\n",
      "    - **vit_hybrid** -- [`ViTHybridConfig`] (ViT Hybrid model)\n",
      "    - **vit_mae** -- [`ViTMAEConfig`] (ViTMAE model)\n",
      "    - **vit_msn** -- [`ViTMSNConfig`] (ViTMSN model)\n",
      "    - **vivit** -- [`VivitConfig`] (ViViT model)\n",
      "    - **wav2vec2** -- [`Wav2Vec2Config`] (Wav2Vec2 model)\n",
      "    - **wav2vec2-conformer** -- [`Wav2Vec2ConformerConfig`] (Wav2Vec2-Conformer model)\n",
      "    - **wavlm** -- [`WavLMConfig`] (WavLM model)\n",
      "    - **whisper** -- [`WhisperConfig`] (Whisper model)\n",
      "    - **xclip** -- [`XCLIPConfig`] (X-CLIP model)\n",
      "    - **xglm** -- [`XGLMConfig`] (XGLM model)\n",
      "    - **xlm** -- [`XLMConfig`] (XLM model)\n",
      "    - **xlm-prophetnet** -- [`XLMProphetNetConfig`] (XLM-ProphetNet model)\n",
      "    - **xlm-roberta** -- [`XLMRobertaConfig`] (XLM-RoBERTa model)\n",
      "    - **xlm-roberta-xl** -- [`XLMRobertaXLConfig`] (XLM-RoBERTa-XL model)\n",
      "    - **xlnet** -- [`XLNetConfig`] (XLNet model)\n",
      "    - **xmod** -- [`XmodConfig`] (X-MOD model)\n",
      "    - **yolos** -- [`YolosConfig`] (YOLOS model)\n",
      "    - **yoso** -- [`YosoConfig`] (YOSO model)\n",
      "\n",
      "Args:\n",
      "    pretrained_model_name_or_path (`str` or `os.PathLike`):\n",
      "        Can be either:\n",
      "\n",
      "            - A string, the *model id* of a pretrained model configuration hosted inside a model repo on\n",
      "              huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`, or\n",
      "              namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.\n",
      "            - A path to a *directory* containing a configuration file saved using the\n",
      "              [`~PretrainedConfig.save_pretrained`] method, or the [`~PreTrainedModel.save_pretrained`] method,\n",
      "              e.g., `./my_model_directory/`.\n",
      "            - A path or url to a saved configuration JSON *file*, e.g.,\n",
      "              `./my_model_directory/configuration.json`.\n",
      "    cache_dir (`str` or `os.PathLike`, *optional*):\n",
      "        Path to a directory in which a downloaded pretrained model configuration should be cached if the\n",
      "        standard cache should not be used.\n",
      "    force_download (`bool`, *optional*, defaults to `False`):\n",
      "        Whether or not to force the (re-)download the model weights and configuration files and override the\n",
      "        cached versions if they exist.\n",
      "    resume_download (`bool`, *optional*, defaults to `False`):\n",
      "        Whether or not to delete incompletely received files. Will attempt to resume the download if such a\n",
      "        file exists.\n",
      "    proxies (`Dict[str, str]`, *optional*):\n",
      "        A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128',\n",
      "        'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.\n",
      "    revision (`str`, *optional*, defaults to `\"main\"`):\n",
      "        The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n",
      "        git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n",
      "        identifier allowed by git.\n",
      "    return_unused_kwargs (`bool`, *optional*, defaults to `False`):\n",
      "        If `False`, then this function returns just the final configuration object.\n",
      "\n",
      "        If `True`, then this functions returns a `Tuple(config, unused_kwargs)` where *unused_kwargs* is a\n",
      "        dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the\n",
      "        part of `kwargs` which has not been used to update `config` and is otherwise ignored.\n",
      "    trust_remote_code (`bool`, *optional*, defaults to `False`):\n",
      "        Whether or not to allow for custom models defined on the Hub in their own modeling files. This option\n",
      "        should only be set to `True` for repositories you trust and in which you have read the code, as it will\n",
      "        execute code present on the Hub on your local machine.\n",
      "    kwargs(additional keyword arguments, *optional*):\n",
      "        The values in kwargs of any keys which are configuration attributes will be used to override the loaded\n",
      "        values. Behavior concerning key/value pairs whose keys are *not* configuration attributes is controlled\n",
      "        by the `return_unused_kwargs` keyword parameter.\n",
      "\n",
      "Examples:\n",
      "\n",
      "```python\n",
      ">>> from transformers import AutoConfig\n",
      "\n",
      ">>> # Download configuration from huggingface.co and cache.\n",
      ">>> config = AutoConfig.from_pretrained(\"bert-base-uncased\")\n",
      "\n",
      ">>> # Download configuration from huggingface.co (user-uploaded) and cache.\n",
      ">>> config = AutoConfig.from_pretrained(\"dbmdz/bert-base-german-cased\")\n",
      "\n",
      ">>> # If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).\n",
      ">>> config = AutoConfig.from_pretrained(\"./test/bert_saved_model/\")\n",
      "\n",
      ">>> # Load a specific configuration file.\n",
      ">>> config = AutoConfig.from_pretrained(\"./test/bert_saved_model/my_configuration.json\")\n",
      "\n",
      ">>> # Change some config attributes when loading a pretrained config.\n",
      ">>> config = AutoConfig.from_pretrained(\"bert-base-uncased\", output_attentions=True, foo=False)\n",
      ">>> config.output_attentions\n",
      "True\n",
      "\n",
      ">>> config, unused_kwargs = AutoConfig.from_pretrained(\n",
      "...     \"bert-base-uncased\", output_attentions=True, foo=False, return_unused_kwargs=True\n",
      "... )\n",
      ">>> config.output_attentions\n",
      "True\n",
      "\n",
      ">>> unused_kwargs\n",
      "{'foo': False}\n",
      "```\n",
      "\u001b[0;31mFile:\u001b[0m      ~/bin/miniconda3/envs/pt-39-6/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "AutoConfig.from_pretrained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-39-6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
