{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | None |  ipex |torch.dynamo | jit | jit+int8 |jit(not freeze)|\n",
    "|---|---|---|---|---|---|---|\n",
    "|throughput (images/s) |256.22|295.87|377.77|465.48|1524.28|233.68|\n",
    "|acc@1|76.66|76.66|76.66|76.66|72.832|76.660|\n",
    "|acc@5|92.67|92.67|92.67|92.67|92.500|92.676|\n",
    "|Self CPU time (s)|15.734|14.079|21.306|13.456|7.885|31.565|\n",
    "|Op|aten::mkldnn_convolution|torch_ipex::convolution_forward_impl|mkldnn::_convolution_pointwise|ipex_prepack::convolution_relu_run|MultiProcessingDataLoaderIter|\n",
    "\n",
    "- Ref:\n",
    "    - torch.jit (V1.0.0): https://pytorch.org/docs/stable/jit.html\n",
    "    - torch.fx (V1.8):    https://pytorch.org/docs/stable/fx.html\n",
    "    - torch._dynoma(v2.0):https://pytorch.org/docs/stable/_dynamo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backends quantized engine is x86\n",
      "=> using pre-trained model 'resnet18'\n",
      "using CPU, this will be slow\n",
      "---- Use NHWC model\n",
      "Iteration: 0, inference time: 0.9421157836914062 sec.\n",
      "Iteration: 1, inference time: 0.8912308216094971 sec.\n",
      "Iteration: 2, inference time: 0.8924376964569092 sec.\n",
      "Iteration: 3, inference time: 0.8748090267181396 sec.\n",
      "Iteration: 4, inference time: 0.8704442977905273 sec.\n",
      "Iteration: 5, inference time: 0.8868789672851562 sec.\n",
      "Iteration: 6, inference time: 0.9002237319946289 sec.\n",
      "Iteration: 7, inference time: 0.8734526634216309 sec.\n",
      "Iteration: 8, inference time: 0.8328640460968018 sec.\n",
      "Iteration: 9, inference time: 0.8893015384674072 sec.\n",
      "Iteration: 10, inference time: 0.8811728954315186 sec.\n",
      "Iteration: 11, inference time: 0.8744597434997559 sec.\n",
      "Iteration: 12, inference time: 0.9049267768859863 sec.\n",
      "Iteration: 13, inference time: 0.8627300262451172 sec.\n",
      "Iteration: 14, inference time: 0.8710191249847412 sec.\n",
      "Iteration: 15, inference time: 0.8708782196044922 sec.\n",
      "Iteration: 16, inference time: 0.8726754188537598 sec.\n",
      "Iteration: 17, inference time: 0.8557348251342773 sec.\n",
      "Iteration: 18, inference time: 0.8597972393035889 sec.\n",
      "Iteration: 19, inference time: 0.8619413375854492 sec.\n",
      " *   Acc@1 76.660 Acc@5 92.676\n",
      "inference latency: 3.410952 ms\n",
      "inference Throughput: 293.173265 images/s\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                               aten::mkldnn_convolution        53.21%        6.922s        53.28%        6.930s      17.326ms           400  \n",
      "                                aten::native_batch_norm        19.72%        2.565s        19.84%        2.581s       6.454ms           400  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        11.29%        1.469s        11.30%        1.470s      69.977ms            21  \n",
      "                          aten::max_pool2d_with_indices         4.51%     586.345ms         4.51%     586.345ms      29.317ms            20  \n",
      "                                       aten::max_pool2d         3.45%     448.486ms         7.96%        1.035s      51.742ms            20  \n",
      "                                       aten::clamp_min_         2.60%     338.005ms         2.60%     338.005ms     994.132us           340  \n",
      "                                             aten::add_         1.66%     215.707ms         1.66%     215.707ms       1.089ms           198  \n",
      "                                     aten::_convolution         1.49%     194.391ms        56.04%        7.290s      18.225ms           400  \n",
      "                                            aten::copy_         1.28%     166.569ms         1.28%     166.569ms     688.302us           242  \n",
      "                                torch_ipex::sum_out_cpu         0.21%      26.717ms         0.22%      28.753ms     479.217us            60  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 13.009s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -W ignore chap05.py --data=/home/taosy/datasets/resnet50 --evaluate --pretrained --profile 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backends quantized engine is x86\n",
      "=> using pre-trained model 'resnet18'\n",
      "using CPU, this will be slow\n",
      "---- Use NHWC model\n",
      "Iteration: 0, inference time: 1.136737585067749 sec.\n",
      "Iteration: 1, inference time: 0.9263460636138916 sec.\n",
      "Iteration: 2, inference time: 0.8179020881652832 sec.\n",
      "Iteration: 3, inference time: 0.8132245540618896 sec.\n",
      "Iteration: 4, inference time: 0.817995548248291 sec.\n",
      "Iteration: 5, inference time: 0.8015108108520508 sec.\n",
      "Iteration: 6, inference time: 0.7988953590393066 sec.\n",
      "Iteration: 7, inference time: 0.8483281135559082 sec.\n",
      "Iteration: 8, inference time: 0.8068685531616211 sec.\n",
      "Iteration: 9, inference time: 0.7877821922302246 sec.\n",
      "Iteration: 10, inference time: 0.7966482639312744 sec.\n",
      "Iteration: 11, inference time: 0.806908369064331 sec.\n",
      "Iteration: 12, inference time: 0.8182797431945801 sec.\n",
      "Iteration: 13, inference time: 0.7996006011962891 sec.\n",
      "Iteration: 14, inference time: 0.9307699203491211 sec.\n",
      "Iteration: 15, inference time: 0.8091058731079102 sec.\n",
      "Iteration: 16, inference time: 0.7842023372650146 sec.\n",
      "Iteration: 17, inference time: 0.7920122146606445 sec.\n",
      "Iteration: 18, inference time: 0.7844908237457275 sec.\n",
      "Iteration: 19, inference time: 0.7591502666473389 sec.\n",
      " *   Acc@1 76.660 Acc@5 92.676\n",
      "inference latency: 3.157436 ms\n",
      "inference Throughput: 316.712695 images/s\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   torch_ipex::convolution_forward_impl        64.15%        8.866s        66.03%        9.125s      22.814ms           400  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        14.50%        2.004s        14.51%        2.005s      95.473ms            21  \n",
      "                                              aten::add         6.77%     936.039ms         6.77%     936.049ms       5.778ms           162  \n",
      "                          aten::max_pool2d_with_indices         5.05%     697.554ms         5.05%     697.554ms      34.878ms            20  \n",
      "                                       aten::max_pool2d         4.03%     557.656ms         9.08%        1.255s      62.761ms            20  \n",
      "                                       aten::clamp_min_         2.70%     372.959ms         2.70%     372.959ms       1.097ms           340  \n",
      "                                            aten::copy_         1.82%     251.733ms         1.82%     251.733ms       1.134ms           222  \n",
      "                                torch_ipex::sum_out_cpu         0.20%      27.947ms         0.23%      31.571ms     526.183us            60  \n",
      "                                     aten::_log_softmax         0.18%      24.759ms         0.18%      24.759ms       1.238ms            20  \n",
      "                              torch_ipex::ipex_MKLSGEMM         0.13%      18.415ms         0.14%      18.721ms     936.050us            20  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 13.821s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -W ignore chap05.py --data=/home/taosy/datasets/resnet50 --evaluate --pretrained --profile --ipex 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backends quantized engine is x86\n",
      "=> using pre-trained model 'resnet18'\n",
      "using CPU, this will be slow\n",
      "---- Use NHWC model\n",
      "Iteration: 0, inference time: 10.389748573303223 sec.\n",
      "Iteration: 1, inference time: 0.7337257862091064 sec.\n",
      "Iteration: 2, inference time: 0.7386317253112793 sec.\n",
      "Iteration: 3, inference time: 0.7330751419067383 sec.\n",
      "Iteration: 4, inference time: 0.7598912715911865 sec.\n",
      "Iteration: 5, inference time: 0.7684614658355713 sec.\n",
      "Iteration: 6, inference time: 0.7686245441436768 sec.\n",
      "Iteration: 7, inference time: 0.7780871391296387 sec.\n",
      "Iteration: 8, inference time: 0.664762020111084 sec.\n",
      "Iteration: 9, inference time: 0.5776910781860352 sec.\n",
      "Iteration: 10, inference time: 0.5536949634552002 sec.\n",
      "Iteration: 11, inference time: 0.5096304416656494 sec.\n",
      "Iteration: 12, inference time: 0.4952576160430908 sec.\n",
      "Iteration: 13, inference time: 0.525954008102417 sec.\n",
      "Iteration: 14, inference time: 0.5546014308929443 sec.\n",
      "Iteration: 15, inference time: 0.5885119438171387 sec.\n",
      "Iteration: 16, inference time: 0.652644157409668 sec.\n",
      "Iteration: 17, inference time: 0.5670764446258545 sec.\n",
      "Iteration: 18, inference time: 0.5719287395477295 sec.\n",
      "Iteration: 19, inference time: 0.5885412693023682 sec.\n",
      " *   Acc@1 76.660 Acc@5 92.676\n",
      "inference latency: 2.386840 ms\n",
      "inference Throughput: 418.963910 images/s\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         mkldnn::_convolution_pointwise        41.67%        8.394s        41.89%        8.437s      17.577ms           480  \n",
      "                      Scheduler.__init__ (dynamo_timed)        28.99%        5.839s        28.99%        5.839s        5.839s             1  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         9.86%        1.986s         9.86%        1.986s      94.588ms            21  \n",
      "          OutputGraph.call_user_compiler (dynamo_timed)         2.78%     560.832ms        45.01%        9.065s        9.065s             1  \n",
      "          create_aot_dispatcher_function (dynamo_timed)         1.80%     363.102ms        46.92%        9.450s     674.968ms            14  \n",
      "                                           aten::detach         1.34%     270.425ms         3.96%     798.158ms      86.898us          9185  \n",
      "                                _compile (dynamo_timed)         1.22%     245.341ms        47.73%        9.614s        9.614s             1  \n",
      "                                             aten::view         1.20%     241.513ms         2.27%     457.090ms     167.863us          2723  \n",
      "                                                 detach         0.88%     178.014ms         1.65%     332.493ms     233.165us          1426  \n",
      "    compile_fx.<locals>.fw_compiler_base (dynamo_timed)         0.88%     176.735ms        39.92%        8.040s        8.040s             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 20.141s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -W ignore chap05.py --data=/home/taosy/datasets/resnet50 --evaluate --pretrained --profile --torch_compile 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backends quantized engine is x86\n",
      "=> using pre-trained model 'resnet18'\n",
      "using CPU, this will be slow\n",
      "---- Use NHWC model\n",
      "---- Use traced model\n",
      "Iteration: 0, inference time: 0.8473875522613525 sec.\n",
      "Iteration: 1, inference time: 0.7797527313232422 sec.\n",
      "Iteration: 2, inference time: 0.6127653121948242 sec.\n",
      "Iteration: 3, inference time: 0.6391487121582031 sec.\n",
      "Iteration: 4, inference time: 0.6518518924713135 sec.\n",
      "Iteration: 5, inference time: 0.5373358726501465 sec.\n",
      "Iteration: 6, inference time: 0.5294387340545654 sec.\n",
      "Iteration: 7, inference time: 0.6049001216888428 sec.\n",
      "Iteration: 8, inference time: 0.605266809463501 sec.\n",
      "Iteration: 9, inference time: 0.5277330875396729 sec.\n",
      "Iteration: 10, inference time: 0.5162153244018555 sec.\n",
      "Iteration: 11, inference time: 0.5274860858917236 sec.\n",
      "Iteration: 12, inference time: 0.512230634689331 sec.\n",
      "Iteration: 13, inference time: 0.5208621025085449 sec.\n",
      "Iteration: 14, inference time: 0.5084717273712158 sec.\n",
      "Iteration: 15, inference time: 0.505312442779541 sec.\n",
      "Iteration: 16, inference time: 0.49515295028686523 sec.\n",
      "Iteration: 17, inference time: 0.5164010524749756 sec.\n",
      "Iteration: 18, inference time: 0.514495849609375 sec.\n",
      "Iteration: 19, inference time: 0.49756693840026855 sec.\n",
      " *   Acc@1 76.660 Acc@5 92.676\n",
      "inference latency: 2.062206 ms\n",
      "inference Throughput: 484.917688 images/s\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     ipex_prepack::convolution_relu_run        32.64%        4.380s        34.11%        4.578s      26.770ms           171  \n",
      "                 ipex_prepack::convolution_add_relu_run        23.38%        3.138s        23.38%        3.138s      20.647ms           152  \n",
      "                                                forward        16.95%        2.274s        84.33%       11.318s     565.893ms            20  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        15.29%        2.052s        15.30%        2.053s      97.776ms            21  \n",
      "                               aten::mkldnn_convolution         3.41%     458.233ms         3.42%     458.748ms      22.937ms            20  \n",
      "                                         dil_max_pool2d         1.80%     241.358ms         1.80%     241.811ms      12.727ms            19  \n",
      "                          ipex_prepack::convolution_run         1.79%     240.132ms         1.80%     241.437ms       4.236ms            57  \n",
      "                                            aten::copy_         1.67%     224.681ms         1.67%     224.681ms     928.434us           242  \n",
      "                                     aten::_convolution         0.77%     103.790ms         4.30%     577.388ms      28.869ms            20  \n",
      "                                       aten::max_pool2d         0.67%      89.267ms         0.92%     124.035ms     124.035ms             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 13.421s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -W ignore chap05.py --data=/home/taosy/datasets/resnet50 --evaluate --pretrained --profile --jit 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backends quantized engine is x86\n",
      "=> using pre-trained model 'resnet18'\n",
      "using CPU, this will be slow\n",
      "---- Use NHWC model\n",
      "Converting int8 model...\n",
      "Convert int8 model done...\n",
      "---- Use traced model\n",
      "Iteration: 0, inference time: 0.2677316665649414 sec.\n",
      "Iteration: 1, inference time: 0.30597376823425293 sec.\n",
      "Iteration: 2, inference time: 0.15057826042175293 sec.\n",
      "Iteration: 3, inference time: 0.15374112129211426 sec.\n",
      "Iteration: 4, inference time: 0.1856060028076172 sec.\n",
      "Iteration: 5, inference time: 0.15639066696166992 sec.\n",
      "Iteration: 6, inference time: 0.16005921363830566 sec.\n",
      "Iteration: 7, inference time: 0.15740251541137695 sec.\n",
      "Iteration: 8, inference time: 0.19242143630981445 sec.\n",
      "Iteration: 9, inference time: 0.15521574020385742 sec.\n",
      "Iteration: 10, inference time: 0.15757989883422852 sec.\n",
      "Iteration: 11, inference time: 0.15602993965148926 sec.\n",
      "Iteration: 12, inference time: 0.18090486526489258 sec.\n",
      "Iteration: 13, inference time: 0.16059374809265137 sec.\n",
      "Iteration: 14, inference time: 0.16392183303833008 sec.\n",
      "Iteration: 15, inference time: 0.1525404453277588 sec.\n",
      "Iteration: 16, inference time: 0.17290687561035156 sec.\n",
      "Iteration: 17, inference time: 0.15431666374206543 sec.\n",
      "Iteration: 18, inference time: 0.15121698379516602 sec.\n",
      "Iteration: 19, inference time: 0.1568901538848877 sec.\n",
      " *   Acc@1 72.480 Acc@5 92.520\n",
      "inference latency: 0.632393 ms\n",
      "inference Throughput: 1581.293965 images/s\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        63.54%        5.877s        63.56%        5.879s     279.934ms            21  \n",
      "                                 quantized::conv2d_relu        12.68%        1.173s        13.78%        1.275s       7.082ms           180  \n",
      "                                      quantized::conv2d        12.18%        1.126s        12.20%        1.128s       5.129ms           220  \n",
      "                                    quantized::add_relu         4.99%     461.434ms         5.01%     463.126ms       2.895ms           160  \n",
      "                                       aten::max_pool2d         2.73%     252.352ms         3.42%     316.122ms      15.806ms            20  \n",
      "                                            aten::clone         1.07%      99.354ms         1.08%      99.937ms       2.498ms            40  \n",
      "                              aten::quantize_per_tensor         0.93%      86.425ms         0.94%      86.511ms       4.326ms            20  \n",
      "                             aten::quantized_max_pool2d         0.69%      63.372ms         0.69%      63.770ms       3.188ms            20  \n",
      "                                      quantized::linear         0.49%      45.273ms         0.50%      45.986ms       2.299ms            20  \n",
      "                                     aten::_log_softmax         0.23%      21.213ms         0.23%      21.213ms       1.061ms            20  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 9.249s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -W ignore chap05.py --data=/home/taosy/datasets/resnet50 --evaluate --pretrained --profile --jit --precision=int8 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backends quantized engine is x86\n",
      "=> using pre-trained model 'resnet18'\n",
      "using CPU, this will be slow\n",
      "---- Use NHWC model\n",
      "---- Use traced model\n",
      "Iteration: 0, inference time: 1.3293442726135254 sec.\n",
      "Iteration: 1, inference time: 1.1122655868530273 sec.\n",
      "Iteration: 2, inference time: 1.1437382698059082 sec.\n",
      "Iteration: 3, inference time: 1.0730292797088623 sec.\n",
      "Iteration: 4, inference time: 1.0750813484191895 sec.\n",
      "Iteration: 5, inference time: 1.025740146636963 sec.\n",
      "Iteration: 6, inference time: 1.0483782291412354 sec.\n",
      "Iteration: 7, inference time: 1.1128673553466797 sec.\n",
      "Iteration: 8, inference time: 1.1823313236236572 sec.\n",
      "Iteration: 9, inference time: 1.117985725402832 sec.\n",
      "Iteration: 10, inference time: 1.1239984035491943 sec.\n",
      "Iteration: 11, inference time: 1.142789363861084 sec.\n",
      "Iteration: 12, inference time: 1.1149365901947021 sec.\n",
      "Iteration: 13, inference time: 1.057476282119751 sec.\n",
      "Iteration: 14, inference time: 1.032416582107544 sec.\n",
      "Iteration: 15, inference time: 1.1341361999511719 sec.\n",
      "Iteration: 16, inference time: 1.1324636936187744 sec.\n",
      "Iteration: 17, inference time: 1.0764434337615967 sec.\n",
      "Iteration: 18, inference time: 1.0722336769104004 sec.\n",
      "Iteration: 19, inference time: 1.0582995414733887 sec.\n",
      " *   Acc@1 76.660 Acc@5 92.676\n",
      "inference latency: 4.279296 ms\n",
      "inference Throughput: 233.683299 images/s\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        29.76%        9.392s        29.76%        9.393s     447.309ms            21  \n",
      "                          ipex_prepack::convolution_run        29.01%        9.157s        30.04%        9.483s      23.707ms           400  \n",
      "                                                forward        20.17%        6.366s        69.86%       22.051s        1.103s            20  \n",
      "                                aten::native_batch_norm        12.18%        3.846s        12.23%        3.860s       9.650ms           400  \n",
      "                                             aten::add_         3.87%        1.221s         3.87%        1.221s       6.164ms           198  \n",
      "                                       aten::clamp_min_         1.51%     475.553ms         1.51%     475.553ms       1.399ms           340  \n",
      "                                         dil_max_pool2d         1.34%     422.311ms         1.34%     423.004ms      21.150ms            20  \n",
      "                                            aten::copy_         1.03%     324.098ms         1.03%     324.098ms       1.339ms           242  \n",
      "        ipex_prepack::createConvolutionPrePackOpContext         0.56%     178.165ms         0.58%     182.894ms     457.235us           400  \n",
      "                                         aten::nll_loss         0.29%      90.165ms         0.29%      90.606ms       4.530ms            20  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 31.565s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -W ignore chap06.py --data=/home/taosy/datasets/resnet50 --evaluate --pretrained --profile --jit 2>/dev/null"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-39-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
