{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Env:\n",
    "    - ```SRP```\n",
    "    - pt-39-4\n",
    "    - run_generation_ipex_llm.py    \n",
    "\n",
    "Demo:\n",
    "- run_generation_ipex_llm.py \n",
    "- new version\n",
    "```\n",
    " ---------- Summary: ----------\n",
    "Inference latency: 1.865 sec.\n",
    "First token average latency: 0.076 sec.\n",
    "Average 2... latency: 0.058 sec.\n",
    "P90 2... latency: 0.074 sec.\n",
    "P99 2... latency: 0.082 sec.\n",
    "```\n",
    "\n",
    "Why:\n",
    "- ONEDNN_VERBOSE=1, no verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_id='EleutherAI/gpt-j-6b', device='cpu', dtype='bfloat16', input_tokens='32', max_new_tokens=32, prompt=None, greedy=False, ipex=True, jit=True, profile=False, benchmark=True, lambada=False, dataset='lambada', accuracy_only=False, num_iter=15, num_warmup=5, batch_size=1, token_latency=True)\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/frontend.py:453: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/frontend.py:460: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/cpu/transformers/models.py:82: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if batch_size <= 0:\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/cpu/transformers/attentions.py:323: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(layer_past[3] + query.shape[1], dtype=torch.long),\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/cpu/transformers/attentions.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(layer_past[3] + query.shape[1], dtype=torch.long),\n",
      "---- Prompt size: 32\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 0, Time: 3.923962 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 1, Time: 2.255098 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 2, Time: 2.487020 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 3, Time: 2.288267 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 4, Time: 2.429842 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 5, Time: 2.125903 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 6, Time: 2.090847 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 7, Time: 1.947863 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 8, Time: 2.029572 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 9, Time: 1.944269 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 10, Time: 1.887748 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 11, Time: 1.722226 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 12, Time: 1.674134 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 13, Time: 1.642210 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 14, Time: 1.585619 sec\n",
      "\n",
      " ---------- Summary: ----------\n",
      "Inference latency: 1.865 sec.\n",
      "First token average latency: 0.076 sec.\n",
      "Average 2... latency: 0.058 sec.\n",
      "P90 2... latency: 0.074 sec.\n",
      "P99 2... latency: 0.082 sec.\n"
     ]
    }
   ],
   "source": [
    "!ONEDNN_VERBOSE=1 TRANSFORMERS_OFFLINE=1 python run_generation_ipex_llm.py --device cpu --benchmark --input-tokens=32 --max-new-tokens 32 \\\n",
    "    --num-iter=15 --num-warmup=5 --batch-size=1 -m EleutherAI/gpt-j-6b \\\n",
    "    --jit --ipex --token-latency --dtype bfloat16 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-39-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
