{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Env:\n",
    "    - ```SRP```\n",
    "    - pt-39-4\n",
    "    - run_generation_ipex_llm.py    \n",
    "\n",
    "Demo:\n",
    "- ```run_generation_ipex_llm.py``` VS ```run_generation_ipex_llm_test.py``` ( only + ipex.optimize())\n",
    "- run_generation_ipex_llm.py: \n",
    "```\n",
    " ---------- Summary: ----------\n",
    "Inference latency: 1.976 sec.\n",
    "First token average latency: 0.071 sec.\n",
    "Average 2... latency: 0.061 sec.\n",
    "P90 2... latency: 0.074 sec.\n",
    "P99 2... latency: 0.089 sec.\n",
    "```\n",
    "- run_generation_ipex_llm_test.py :\n",
    "```\n",
    "---------- Summary: ----------\n",
    "Inference latency: 2.720 sec.\n",
    "First token average latency: 0.112 sec.\n",
    "Average 2... latency: 0.084 sec.\n",
    "P90 2... latency: 0.094 sec.\n",
    "P99 2... latency: 0.113 sec.\n",
    "```\n",
    "\n",
    "Why:\n",
    "- ONEDNN_VERBOSE=1, no verbose ?\n",
    "- ONEDNN_VERBOSE=1, verbose is ok if ipex.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_id='EleutherAI/gpt-j-6b', device='cpu', dtype='bfloat16', input_tokens='32', max_new_tokens=32, prompt=None, greedy=False, ipex=True, jit=True, profile=False, benchmark=True, lambada=False, dataset='lambada', accuracy_only=False, num_iter=15, num_warmup=5, batch_size=1, token_latency=True)\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/frontend.py:453: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/frontend.py:460: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/cpu/transformers/models.py:82: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if batch_size <= 0:\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/cpu/transformers/attentions.py:323: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(layer_past[3] + query.shape[1], dtype=torch.long),\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/cpu/transformers/attentions.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(layer_past[3] + query.shape[1], dtype=torch.long),\n",
      "---- Prompt size: 32\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 0, Time: 4.058582 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 1, Time: 2.248238 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 2, Time: 2.315439 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 3, Time: 2.303294 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 4, Time: 2.307833 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 5, Time: 2.305859 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 6, Time: 2.364268 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 7, Time: 2.208955 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 8, Time: 2.078389 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 9, Time: 2.034640 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 10, Time: 1.874049 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 11, Time: 1.817646 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 12, Time: 1.734456 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 13, Time: 1.675376 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 14, Time: 1.662006 sec\n",
      "\n",
      " ---------- Summary: ----------\n",
      "Inference latency: 1.976 sec.\n",
      "First token average latency: 0.071 sec.\n",
      "Average 2... latency: 0.061 sec.\n",
      "P90 2... latency: 0.074 sec.\n",
      "P99 2... latency: 0.089 sec.\n"
     ]
    }
   ],
   "source": [
    "!ONEDNN_VERBOSE=1 TRANSFORMERS_OFFLINE=1 python run_generation_ipex_llm.py --device cpu --benchmark --input-tokens=32 --max-new-tokens 32 \\\n",
    "    --num-iter=15 --num-warmup=5 --batch-size=1 -m EleutherAI/gpt-j-6b \\\n",
    "    --jit --ipex --token-latency --dtype bfloat16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_id='EleutherAI/gpt-j-6b', device='cpu', dtype='bfloat16', input_tokens='32', max_new_tokens=32, prompt=None, greedy=False, ipex=True, jit=True, profile=False, benchmark=True, lambada=False, dataset='lambada', accuracy_only=False, num_iter=15, num_warmup=5, batch_size=1, token_latency=True)\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/frontend.py:453: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/frontend.py:460: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/cpu/transformers/models.py:82: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if batch_size <= 0:\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/cpu/transformers/attentions.py:323: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(layer_past[3] + query.shape[1], dtype=torch.long),\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/cpu/transformers/attentions.py:323: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(layer_past[3] + query.shape[1], dtype=torch.long),\n",
      "---- Prompt size: 32\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 0, Time: 3.112213 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 1, Time: 2.446426 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 2, Time: 2.486102 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 3, Time: 2.556310 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 4, Time: 2.649721 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 5, Time: 2.706119 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 6, Time: 2.880409 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 7, Time: 2.985964 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 8, Time: 2.922127 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 9, Time: 2.829184 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 10, Time: 2.528999 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 11, Time: 2.602707 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 12, Time: 2.599842 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 13, Time: 2.620600 sec\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 14, Time: 2.520287 sec\n",
      "\n",
      " ---------- Summary: ----------\n",
      "Inference latency: 2.720 sec.\n",
      "First token average latency: 0.112 sec.\n",
      "Average 2... latency: 0.084 sec.\n",
      "P90 2... latency: 0.094 sec.\n",
      "P99 2... latency: 0.113 sec.\n"
     ]
    }
   ],
   "source": [
    "!ONEDNN_VERBOSE=0 TRANSFORMERS_OFFLINE=1 python run_generation_ipex_llm_test.py --device cpu --benchmark --input-tokens=32 --max-new-tokens 32 \\\n",
    "    --num-iter=15 --num-warmup=5 --batch-size=1 -m EleutherAI/gpt-j-6b \\\n",
    "    --jit --ipex --token-latency --dtype bfloat16 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-39-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
