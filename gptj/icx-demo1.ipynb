{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Env:\n",
    "    - ```ICX```\n",
    "    - pt-39-4\n",
    "- Demo:\n",
    "    - 必须同时具备 --jit and --ipex\n",
    "    - no \"--jit\" and no \"--ipex\"\n",
    "    - Performance\n",
    "```\n",
    "Inference latency: 6.235 sec.\n",
    "First token average latency: 0.606 sec.\n",
    "Average 2... latency: 0.182 sec.\n",
    "P90 2... latency: 0.303 sec.\n",
    "P99 2... latency: 0.542 sec.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_id='EleutherAI/gpt-j-6b', device='cpu', dtype='bfloat16', input_tokens='32', max_new_tokens=32, prompt=None, greedy=False, ipex=True, ipex_tpp=False, jit=True, num_iter=15, num_warmup=5, batch_size=1, token_latency=True, enable_xpu_optimize=False)\n",
      "---- Prompt size: 32\n",
      "past_lenght: tensor([0])\n",
      "past_lenght: tensor([0])\n",
      "past_lenght: tensor([0])\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 0, Time: 25.518749 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 1, Time: 7.882284 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 2, Time: 5.314929 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 3, Time: 7.707387 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 4, Time: 8.171381 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 5, Time: 8.096198 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 6, Time: 6.467432 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 7, Time: 5.349080 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 8, Time: 5.468357 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 9, Time: 5.562775 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 10, Time: 5.535112 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 11, Time: 7.037495 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 12, Time: 7.035503 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 13, Time: 6.386568 sec\n",
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 14, Time: 5.409992 sec\n",
      "\n",
      " ---------- Summary: ----------\n",
      "Inference latency: 6.235 sec.\n",
      "First token average latency: 0.606 sec.\n",
      "Average 2... latency: 0.182 sec.\n",
      "P90 2... latency: 0.303 sec.\n",
      "P99 2... latency: 0.542 sec.\n"
     ]
    }
   ],
   "source": [
    "!python run_generation.py --device cpu --input-tokens=32 --max-new-tokens 32 \\\n",
    "    --num-iter=15 --num-warmup=5 --batch-size=1 -m EleutherAI/gpt-j-6b \\\n",
    "    --jit --ipex --token-latency --dtype bfloat16 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_id='EleutherAI/gpt-j-6b', device='cpu', dtype='bfloat16', input_tokens='32', max_new_tokens=32, prompt=None, greedy=False, ipex=True, ipex_tpp=False, jit=False, num_iter=15, num_warmup=5, batch_size=1, token_latency=True, enable_xpu_optimize=False)\n",
      "/home/taosy/repo/pytorch/vision/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/frontend.py:453: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n",
      "/home/taosy/repo/intel-innersource/frameworks.ai.pytorch.ipex-cpu/intel_extension_for_pytorch/frontend.py:460: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\n",
      "---- Prompt size: 32\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/taosy/repo/shaoyu/ai-opt-demo/gptj/run_generation.py\", line 166, in <module>\n",
      "    output = model.generate(\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/transformers/generation/utils.py\", line 1534, in generate\n",
      "    return self.beam_search(\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/transformers/generation/utils.py\", line 2951, in beam_search\n",
      "    outputs = self(\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1502, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py\", line 878, in forward\n",
      "    transformer_outputs = self.transformer(\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1502, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py\", line 623, in forward\n",
      "    if len(past_key_values[0]) == 4:\n",
      "TypeError: object of type 'NoneType' has no len()\n"
     ]
    }
   ],
   "source": [
    "!python run_generation.py --device cpu --input-tokens=32 --max-new-tokens 32 \\\n",
    "    --num-iter=15 --num-warmup=5 --batch-size=1 -m EleutherAI/gpt-j-6b \\\n",
    "    --ipex --token-latency --dtype bfloat16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_id='EleutherAI/gpt-j-6b', device='cpu', dtype='bfloat16', input_tokens='32', max_new_tokens=32, prompt=None, greedy=False, ipex=False, ipex_tpp=False, jit=True, num_iter=15, num_warmup=5, batch_size=1, token_latency=True, enable_xpu_optimize=False)\n",
      "---- Prompt size: 32\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "past_lenght: tensor([0])\n",
      "/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py:633: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if batch_size <= 0:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/_ops.py\", line 712, in __getattr__\n",
      "    op, overload_names = torch._C._jit_get_operation(qualified_op_name)\n",
      "RuntimeError: No such operator torch_ipex::rotary_position_embedding\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/taosy/repo/shaoyu/ai-opt-demo/gptj/run_generation.py\", line 166, in <module>\n",
      "    output = model.generate(\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/transformers/generation/utils.py\", line 1534, in generate\n",
      "    return self.beam_search(\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/transformers/generation/utils.py\", line 3011, in beam_search\n",
      "    self_jit = torch.jit.trace(self, example_inputs, strict=False)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/jit/_trace.py\", line 795, in trace\n",
      "    return trace_module(\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/jit/_trace.py\", line 1057, in trace_module\n",
      "    module._c._create_method_from_trace(\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1502, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1492, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py\", line 878, in forward\n",
      "    transformer_outputs = self.transformer(\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1502, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1492, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py\", line 713, in forward\n",
      "    outputs = block(\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1502, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1492, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py\", line 331, in forward\n",
      "    attn_outputs = self.attn(\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1502, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1492, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py\", line 213, in forward\n",
      "    torch.ops.torch_ipex.rotary_position_embedding(\n",
      "  File \"/home/taosy/bin/miniconda3/envs/pt-39-4/lib/python3.9/site-packages/torch/_ops.py\", line 716, in __getattr__\n",
      "    raise AttributeError(\n",
      "AttributeError: '_OpNamespace' 'torch_ipex' object has no attribute 'rotary_position_embedding'\n"
     ]
    }
   ],
   "source": [
    "!python run_generation.py --device cpu --input-tokens=32 --max-new-tokens 32 \\\n",
    "    --num-iter=15 --num-warmup=5 --batch-size=1 -m EleutherAI/gpt-j-6b \\\n",
    "    --jit --token-latency --dtype bfloat16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-39-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
