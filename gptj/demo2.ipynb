{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Env: py-39-4: 能够完整运行  --jit --ipex\n",
    "    - innersource-ipex ( 174a1874adf ）: 2.1.0+git174a187\n",
    "    - sandbox-transformers ( 1720855 ) : 4.28.1\n",
    "```\n",
    "Inference latency: 6.855 sec.\n",
    "First token average latency: 0.681 sec.\n",
    "Average 2... latency: 0.199 sec.\n",
    "P90 2... latency: 0.295 sec.\n",
    "P99 2... latency: 1.128 sec.\n",
    "====================\n",
    "prim_kind      impl          ncalls  time(ms)   overall%  agg_ncalls(avg)  agg_time(ms)  agg_overall%\n",
    "inner_product  x64:gemm:jit  81965   123431.87  99.53     81965.00         123431.87     99.53\n",
    "reorder        jit:uni       169     587.51     0.47      41067.00         124019.38     100.00\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ONEDNN_VERBOSE=1 python run_generation.py --device cpu --input-tokens=32 --max-new-tokens 32 \\\n",
    "    --num-iter=15 --num-warmup=5 --batch-size=1 -m EleutherAI/gpt-j-6b \\\n",
    "    --jit --ipex --token-latency --dtype bfloat16 > /tmp/gptj.log 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference latency: 6.855 sec.\n",
      "First token average latency: 0.681 sec.\n",
      "Average 2... latency: 0.199 sec.\n",
      "P90 2... latency: 0.295 sec.\n",
      "P99 2... latency: 1.128 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "prim_kind      impl          ncalls  time(ms)   overall%  agg_ncalls(avg)  agg_time(ms)  agg_overall%\n",
      "inner_product  x64:gemm:jit  81965   123431.87  99.53     81965.00         123431.87     99.53\n",
      "reorder        jit:uni       169     587.51     0.47      41067.00         124019.38     100.00\n"
     ]
    }
   ],
   "source": [
    "!tail -n 5 /tmp/gptj.log\n",
    "!echo ====================\n",
    "!/home/taosy/repo/github/oneDNN/scripts/verbose_converter/verbose_converter.py -i /tmp/gptj.log -g breakdown -k prim_kind  impl | column -t -s,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ONEDNN_VERBOSE=1 python run_generation-2.py --device cpu --input-tokens=32 --max-new-tokens 32 \\\n",
    "    --num-iter=15 --num-warmup=5 --batch-size=1 -m EleutherAI/gpt-j-6b \\\n",
    "    --jit --ipex --token-latency --dtype bfloat16 --profile > /tmp/gptj-prof_1.log 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Once upon a time, there existed a little girl, who liked to have adventures. She wanted to go to places and meet new people, and have fun. One day, she decided to go on an adventure. She packed her bags, and set off on her journey.\\n\\nThe little girl walked and walked,'] [32]\n",
      "Iteration: 14, Time: 5.689841 sec\n",
      "\n",
      " ---------- Summary: ----------\n",
      "Inference latency: 5.653 sec.\n",
      "First token average latency: 0.484 sec.\n",
      "Average 2... latency: 0.167 sec.\n",
      "P90 2... latency: 0.170 sec.\n",
      "P99 2... latency: 0.192 sec.\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                               ipex_prepack::linear_run        51.33%       65.121s        51.54%       65.383s       1.208ms         54127  \n",
      "                                torch_ipex::ipex_linear        20.46%       25.950s        20.47%       25.968s      25.459ms          1020  \n",
      "                          ipex_prepack::linear_gelu_run        13.23%       16.788s        13.31%       16.886s       1.259ms         13412  \n",
      "                           ipex_prepack::linear_add_run         7.69%        9.751s         7.72%        9.790s     729.953us         13412  \n",
      "                                            aten::fill_         1.45%        1.837s         1.45%        1.837s      19.016us         96613  \n",
      "                                                forward         1.08%        1.369s        90.20%      114.427s     237.400ms           482  \n",
      "                                             aten::topk         0.53%     666.170ms         0.53%     666.170ms       1.385ms           481  \n",
      "               ipex::iakv_sdp::reduction_private_result         0.39%     497.216ms         0.39%     497.216ms      38.189us         13020  \n",
      "                                aten::native_layer_norm         0.38%     480.914ms         0.40%     504.199ms      37.112us         13586  \n",
      "                                              aten::add         0.37%     471.825ms         0.37%     471.831ms      15.826us         29814  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 126.859s\n",
      "\n",
      "====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prim_kind      impl          ncalls  time(ms)   overall%  agg_ncalls(avg)  agg_time(ms)  agg_overall%\n",
      "inner_product  x64:gemm:jit  81965   113372.98  99.29     81965.00         113372.98     99.29\n",
      "reorder        jit:uni       169     816.02     0.71      41067.00         114189.01     100.00\n"
     ]
    }
   ],
   "source": [
    "!tail -n 25 /tmp/gptj-prof_1.log \n",
    "!echo ====================\n",
    "!/home/taosy/repo/github/oneDNN/scripts/verbose_converter/verbose_converter.py -i /tmp/gptj-prof_1.log  -g breakdown -k prim_kind  impl | column -t -s,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-39-4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
